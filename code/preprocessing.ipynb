{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions to be used multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "\n",
    "# Calculate the z-score for a specified column\n",
    "def get_z_scores(column_name):\n",
    "    z_scores = np.abs((df[column_name] - df[column_name].mean()) / df[column_name].std())\n",
    "    return z_scores\n",
    "\n",
    "# Remove outliers from the DataFrame based on z-scores\n",
    "def remove_outliers(z_scores):\n",
    "    # Define a threshold for outlier detection (e.g., z-score > 3)\n",
    "    threshold = 3\n",
    "\n",
    "    # Filter rows where z-score exceeds the threshold\n",
    "    outliers = df[z_scores > threshold]\n",
    "\n",
    "    # Remove outliers from the DataFrame\n",
    "    cleaned_df = df[z_scores <= threshold]\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HS_Cigar_Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/yldjq0js2ng8cysrh56tt9xw0000gn/T/ipykernel_23355/2144815280.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouliers in data were cleaned and inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read data from the MySQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM cdc_cigar_use\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Specify the columns with potential outliers\n",
    "dirty_columns = [\n",
    "    'Greater_Risk_Data_Value',\n",
    "    'Greater_Risk_Low_Confidence_Limit',\n",
    "    'Greater_Risk_High_Confidence_Limit',\n",
    "    'Lesser_Risk_Data_Value',\n",
    "    'Lesser_Risk_Low_Confidence_Limit',\n",
    "    'Lesser_Risk_High_Confidence_Limit'\n",
    "]\n",
    "\n",
    "# Iterate through the columns to remove outliers\n",
    "for column in dirty_columns:\n",
    "    z_scores = get_z_scores(column)\n",
    "    cleaned_df = remove_outliers(z_scores)\n",
    "\n",
    "# Reconnect\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Truncate the existing table to remove all data\n",
    "truncate_query = \"TRUNCATE TABLE cdc_cigar_use\"\n",
    "cursor.execute(truncate_query)\n",
    "conn.commit()\n",
    "\n",
    "# Insert the cleaned data into the MySQL table\n",
    "insert_query = (\n",
    "    \"INSERT INTO cdc_cigar_use \"\n",
    "    \"(YEAR, LocationAbbr, LocationDesc, DataSource, Topic, Subtopic, \"\n",
    "    \"ShortQuestionText, Greater_Risk_Question, Description, Data_Value_Symbol, \"\n",
    "    \"Data_Value_Type, Greater_Risk_Data_Value, Greater_Risk_Data_Value_Footnote_Symbol, \"\n",
    "    \"Greater_Risk_Data_Value_Footnote, Greater_Risk_Low_Confidence_Limit, \"\n",
    "    \"Greater_Risk_High_Confidence_Limit, Lesser_Risk_Question, Lesser_Risk_Data_Value, \"\n",
    "    \"Lesser_Risk_Data_Value_Footnote_Symbol, Lesser_Risk_Data_Value_Footnote, \"\n",
    "    \"Lesser_Risk_Low_Confidence_Limit, Lesser_Risk_High_Confidence_Limit, Sample_Size, \"\n",
    "    \"Sex, Race, Grade, SexualIdentity, SexOfSexualContacts, GeoLocation, TopicId, \"\n",
    "    \"SubTopicID, QuestionCode, LocationId, StratID1, StratID2, StratID3, StratID4, \"\n",
    "    \"StratID5, StratificationType, StratID6) \"\n",
    "    \"VALUES \"\n",
    "    \"(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\n",
    "    \"%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    ")\n",
    "\n",
    "for row in cleaned_df.itertuples(index=False):\n",
    "    cursor.execute(insert_query, row)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Ouliers in data were cleaned and inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/yldjq0js2ng8cysrh56tt9xw0000gn/T/ipykernel_32722/3956154861.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in data were cleaned and inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "# Read data from the MySQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM cms_chronic_conditions\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Columns to clean and remove outliers\n",
    "dirty_columns = [\n",
    "    'Prvlnc',\n",
    "    'Tot_Mdcr_Stdzd_Pymt_PC',\n",
    "    'Tot_Mdcr_Pymt_PC',\n",
    "    'Hosp_Readmsn_Rate',\n",
    "    'ER_Visits_Per_1000_Benes',\n",
    "    ]\n",
    "\n",
    "# Iterate through the columns to remove outliers\n",
    "for column in dirty_columns:\n",
    "    z_scores = get_z_scores(column)\n",
    "    df = remove_outliers(z_scores)\n",
    "\n",
    "# Reconnect to MySQL for data insertion\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Truncate the existing table to remove all data\n",
    "truncate_query = \"TRUNCATE TABLE cms_chronic_conditions\"\n",
    "cursor.execute(truncate_query)\n",
    "conn.commit()\n",
    "\n",
    "# Batch insert the cleaned data into the MySQL table\n",
    "insert_query = (\n",
    "    \"INSERT INTO cms_chronic_conditions \"\n",
    "    \"(Bene_Geo_Lvl, Bene_Geo_Desc, Bene_Geo_Cd, Bene_Age_Lvl, Bene_Demo_Lvl, \"\n",
    "    \"Bene_Demo_Desc, Bene_Cond, Prvlnc, Tot_Mdcr_Stdzd_Pymt_PC, Tot_Mdcr_Pymt_PC, \"\n",
    "    \"Hosp_Readmsn_Rate, ER_Visits_Per_1000_Benes) \"\n",
    "    \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    ")\n",
    "\n",
    "# Convert DataFrame to list of tuples for batch insert\n",
    "data_to_insert = df.values.tolist()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Outliers in data were cleaned and inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVD Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/yldjq0js2ng8cysrh56tt9xw0000gn/T/ipykernel_32722/2606781736.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in CVD data were cleaned and inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read data from the MySQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM cdv_cleaned\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Columns to clean and remove outliers\n",
    "dirty_columns = [\n",
    "    'Height_cm',\n",
    "    'Weight_kg',\n",
    "    'BMI',\n",
    "    'Alcohol_Consumption',\n",
    "    'Fruit_Consumption',\n",
    "    'Green_Vegetables_Consumption',\n",
    "    'FriedPotato_Consumption',\n",
    "]\n",
    "\n",
    "# Iterate through the columns to remove outliers\n",
    "for column in dirty_columns:\n",
    "    z_scores = get_z_scores(column)\n",
    "    df = remove_outliers(z_scores)\n",
    "\n",
    "# Reconnect to MySQL for data insertion\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Truncate the existing table to remove all data\n",
    "truncate_query = \"TRUNCATE TABLE cdv_cleaned\"\n",
    "cursor.execute(truncate_query)\n",
    "conn.commit()\n",
    "\n",
    "# Batch insert the cleaned data into the MySQL table\n",
    "insert_query = (\n",
    "    \"INSERT INTO cdv_cleaned \"\n",
    "    \"(General_Health, Checkup, Exercise, Heart_Disease, Skin_Cancer, Other_Cancer, \"\n",
    "    \"Depression, Diabetes, Arthritis, Sex, Age_Category, Height_cm, Weight_kg, \"\n",
    "    \"BMI, Smoking_History, Alcohol_Consumption, Fruit_Consumption, \"\n",
    "    \"Green_Vegetables_Consumption, FriedPotato_Consumption) \"\n",
    "    \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    ")\n",
    "\n",
    "# Convert DataFrame to list of tuples for batch insert\n",
    "data_to_insert = df.values.tolist()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Outliers in CVD data were cleaned and inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart 2020 Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/yldjq0js2ng8cysrh56tt9xw0000gn/T/ipykernel_32722/1397861756.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Heart 2020 Cleaned data were cleaned and inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read data from the MySQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM heart_2020_cleaned\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Columns to clean and remove outliers\n",
    "dirty_columns = [\n",
    "    'BMI',\n",
    "    'PhysicalHealth',\n",
    "    'MentalHealth',\n",
    "    'SleepTime',\n",
    "]\n",
    "\n",
    "# Iterate through the columns to remove outliers\n",
    "for column in dirty_columns:\n",
    "    z_scores = get_z_scores(column)\n",
    "    df = remove_outliers(z_scores)\n",
    "\n",
    "# Reconnect to MySQL for data insertion\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Truncate the existing table to remove all data\n",
    "truncate_query = \"TRUNCATE TABLE heart_2020_cleaned\"\n",
    "cursor.execute(truncate_query)\n",
    "conn.commit()\n",
    "\n",
    "# Batch insert the cleaned data into the MySQL table\n",
    "insert_query = (\n",
    "    \"INSERT INTO heart_2020_cleaned \"\n",
    "    \"(HeartDisease, BMI, Smoking, AlcoholDrinking, Stroke, PhysicalHealth, MentalHealth, \"\n",
    "    \"DiffWalking, Sex, AgeCategory, Race, Diabetic, PhysicalActivity, GenHealth, \"\n",
    "    \"SleepTime, Asthma, KidneyDisease, SkinCancer) \"\n",
    "    \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    ")\n",
    "\n",
    "# Convert DataFrame to list of tuples for batch insert\n",
    "data_to_insert = df.values.tolist()\n",
    "cursor.executemany(insert_query, data_to_insert)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Outliers in Heart 2020 Cleaned data were cleaned and inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart 2022 with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/yldjq0js2ng8cysrh56tt9xw0000gn/T/ipykernel_32722/13198041.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in Heart 2022 data with NaN values were cleaned and inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Connect to MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read data from the MySQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM heart_2022_with_nans\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Columns to clean and remove outliers\n",
    "dirty_columns = [\n",
    "    'HeightInMeters',\n",
    "    'WeightInKilograms',\n",
    "    'BMI',\n",
    "    'PhysicalHealthDays',\n",
    "    'MentalHealthDays',\n",
    "    'SleepHours',\n",
    "]\n",
    "\n",
    "# Iterate through the columns to remove outliers\n",
    "for column in dirty_columns:\n",
    "    z_scores = get_z_scores(column)\n",
    "    df = remove_outliers(z_scores)\n",
    "\n",
    "# Reconnect to MySQL for data insertion\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Truncate the existing table to remove all data\n",
    "truncate_query = \"TRUNCATE TABLE heart_2022_with_nans\"\n",
    "cursor.execute(truncate_query)\n",
    "conn.commit()\n",
    "\n",
    "# Batch insert the cleaned data into the MySQL table\n",
    "insert_query = (\n",
    "    \"INSERT INTO heart_2022_with_nans \"\n",
    "    \"(State, Sex, GeneralHealth, PhysicalHealthDays, MentalHealthDays, LastCheckupTime, \"\n",
    "    \"PhysicalActivities, SleepHours, RemovedTeeth, HadHeartAttack, HadAngina, HadStroke, \"\n",
    "    \"HadAsthma, HadSkinCancer, HadCOPD, HadDepressiveDisorder, HadKidneyDisease, \"\n",
    "    \"HadArthritis, HadDiabetes, DeafOrHardOfHearing, BlindOrVisionDifficulty, \"\n",
    "    \"DifficultyConcentrating, DifficultyWalking, DifficultyDressingBathing, \"\n",
    "    \"DifficultyErrands, SmokerStatus, ECigaretteUsage, ChestScan, RaceEthnicityCategory, \"\n",
    "    \"AgeCategory, HeightInMeters, WeightInKilograms, BMI, AlcoholDrinkers, HIVTesting, \"\n",
    "    \"FluVaxLast12, PneumoVaxEver, TetanusLast10Tdap, HighRiskLastYear, CovidPos) \"\n",
    "    \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\n",
    "    \"%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    ")\n",
    "\n",
    "# Convert DataFrame to list of tuples for batch insert\n",
    "data_to_insert = df.values.tolist()\n",
    "\n",
    "# Batch insert with smaller batches\n",
    "batch_size = 1000  # Adjust batch size as needed\n",
    "num_rows = len(data_to_insert)\n",
    "\n",
    "for i in range(0, num_rows, batch_size):\n",
    "    batch_data = data_to_insert[i:i + batch_size]\n",
    "    cursor.executemany(insert_query, batch_data)\n",
    "    conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Outliers in Heart 2022 data with NaN values were cleaned and inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex  Chest_pain_type   BP  Cholesterol  FBS_over_120  EKG_results  \\\n",
      "0   29   1                2  130          204             0            2   \n",
      "1   34   0                2  118          210             0            0   \n",
      "2   35   1                4  120          198             0            0   \n",
      "3   37   0                3  120          215             0            0   \n",
      "4   38   1                1  120          231             0            0   \n",
      "\n",
      "   Max_HR  Exercise_angina  ST_depression  Slope_of_ST  \\\n",
      "0     202                0            0.0            1   \n",
      "1     192                0            0.7            1   \n",
      "2     130                1            1.6            2   \n",
      "3     170                0            0.0            1   \n",
      "4     182                1            3.8            2   \n",
      "\n",
      "   Number_of_vessels_fluro  Thallium  Heart_Disease  \n",
      "0                        0         3              0  \n",
      "1                        0         3              0  \n",
      "2                        0         7              0  \n",
      "3                        0         3              0  \n",
      "4                        0         7              0  \n",
      "    Age  Sex     BP  Cholesterol  FBS_over_120  EKG_results  Max_HR  \\\n",
      "0  29.0  1.0  130.0        204.0           0.0          2.0   202.0   \n",
      "1  34.0  0.0  118.0        210.0           0.0          0.0   192.0   \n",
      "2  35.0  1.0  120.0        198.0           0.0          0.0   130.0   \n",
      "3  37.0  0.0  120.0        215.0           0.0          0.0   170.0   \n",
      "4  38.0  1.0  120.0        231.0           0.0          0.0   182.0   \n",
      "\n",
      "   ST_depression  Number_of_vessels_fluro  Heart_Disease  Chest_pain_type_4  \\\n",
      "0            0.0                      0.0            0.0                1.0   \n",
      "1            0.7                      0.0            0.0                1.0   \n",
      "2            1.6                      0.0            0.0                0.0   \n",
      "3            0.0                      0.0            0.0                0.0   \n",
      "4            3.8                      0.0            0.0                0.0   \n",
      "\n",
      "   Chest_pain_type_3  Chest_pain_type_1  Exercise_angina_1  Slope_of_ST_2  \\\n",
      "0                0.0                0.0                0.0            0.0   \n",
      "1                0.0                0.0                0.0            0.0   \n",
      "2                0.0                1.0                1.0            1.0   \n",
      "3                1.0                0.0                0.0            0.0   \n",
      "4                0.0                0.0                1.0            1.0   \n",
      "\n",
      "   Thallium_7  Thallium_6  \n",
      "0         0.0         0.0  \n",
      "1         0.0         0.0  \n",
      "2         0.0         1.0  \n",
      "3         0.0         0.0  \n",
      "4         0.0         1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/yldjq0js2ng8cysrh56tt9xw0000gn/T/ipykernel_80209/3275656459.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Connect to MySQL database and fetch data\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"monty\",\n",
    "    password=\"sushiSQL\",\n",
    "    database=\"HealthCareAnalytics\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Read data from the MySQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM heart_disease_prediction\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the MySQL connection\n",
    "conn.close()\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand the data\n",
    "print(df.head())\n",
    "\n",
    "# Remove entries with 40% or more missing values\n",
    "threshold = len(df.columns) * 0.4\n",
    "df.dropna(thresh=threshold, inplace=True)\n",
    "\n",
    "# Fill missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Perform one-hot encoding for categorical variables\n",
    "categorical_cols = ['Chest_pain_type', 'Exercise_angina', 'Slope_of_ST', 'Thallium']\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "encoded_cols = encoder.fit_transform(df_filled[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_cols.toarray(), columns=[f\"{col}_{val}\" for col in categorical_cols for val in df[col].unique()[1:]])\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "df_processed = pd.concat([df_filled.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "\n",
    "# Display the preprocessed DataFrame\n",
    "print(df_processed.head())\n",
    "\n",
    "# Now you can proceed with defining features (X) and target variable (y), splitting data, training models, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
